{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4aa936",
   "metadata": {},
   "source": [
    "# Instructions of the Project\n",
    "\n",
    "- **Follow the universal workflow of DLWP 4.5 (1st edition) for a dataset of your choice.**\n",
    "- You can use the tensorflow datasets, MNIST, Reuters, IMDB and Boston Housing Price, or an external dataset. Work exclusively in a Jupyter notebook.\n",
    "- **Do not begin your report with data visualisation**. No marks are allocated for preliminary data exploration. However, you may wish to investigate the dataset in support of your interpretation of results.\n",
    "- You can only use DLWP Part 1 layers (Chapters 1–4) i.e. **restrict your models to tensorflow sequential Dense and Dropout layers**.\n",
    "- Your Jupyter notebook should read as a report – not just a sequence of code cells. Structure your report with markdown headings, subheadings, tables etc.\n",
    "- You can use as much DLWP code and code from the video notebooks as you wish but you must reference all code that is not original: **credit will be given for model assembly using third-party code, and extra credit may be awarded for original code.**\n",
    "\n",
    "Export your Jupyter notebook to html and submit. Do not submit your notebook or any data files. Submit only the html export of your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41c157",
   "metadata": {},
   "source": [
    "# Projected Timeline\n",
    "\n",
    "| Date   | Day | Planned Time      | Main Goals                                                                                 | Done |\n",
    "| ------ | --- | ----------------- | ------------------------------------------------------------------------------------------ | ---- |\n",
    "| Feb 18 | Wed | ~3 h (night)      | Intro markdown: describe MNIST, problem type, metric. Outline notebook sections.           | Yes  |\n",
    "| Feb 19 | Thu | ~3 h (night)      | Load MNIST, preprocess (flatten, scale, one‑hot), create train/validation split.           | Yes  |\n",
    "| Feb 20 | Fri | ~3 h (night)      | Implement and train a small baseline model. Record training/validation accuracy.           | Yes  |\n",
    "| Feb 21 | Sat | **0 h (day off)** | No work – fully off.                                                                       | Yes  |\n",
    "| Feb 22 | Sun | **0 h (day off)** | No work – fully off.                                                                       | Yes  |\n",
    "| Feb 23 | Mon | ~3 h (night)      | Compare baseline to trivial baseline; write markdown reflecting on baseline performance.   |  Yes |\n",
    "| Feb 24 | Tue | ~3 h (night)      | Build a larger model to overfit. Train and note signs of overfitting.                      | Yes  |\n",
    "| Feb 25 | Wed | ~3 h (night)      | Add Dropout / reduce capacity. Run 1–2 regularized experiments and explain changes.        |      |\n",
    "| Feb 26 | Thu | ~3 h (night)      | Simple hyperparameter tuning (units, epochs, batch size). Create a small results table.    |      |\n",
    "| Feb 27 | Fri | ~3 h (night)      | Choose best model via validation and evaluate on the test set. Start interpretation text.  |      |\n",
    "| Feb 28 | Sat | 1–3 h (flex)      | Finish interpretation, polish markdown, add references, full run-through and final checks. |      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb1470",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "You’re being asked to basically “recreate” the DLWP 4.5 workflow on any small dataset, then write it up nicely in a notebook as if it were a mini paper.\n",
    "\n",
    "## 1. What the “universal workflow” means\n",
    "\n",
    "DLWP 4.5 (1st ed.) lays out these core steps for a machine learning project: [github](https://github.com/aakashns/deep-learning-workbook)\n",
    "\n",
    "1. Define the problem and dataset\n",
    "2. Choose a success metric\n",
    "3. Decide your evaluation protocol (train/val/test split etc.)\n",
    "4. Build a first, simple model (baseline)\n",
    "5. Make a model that overfits (increase capacity, train longer, etc.)\n",
    "6. Regularize and tune hyperparameters using the validation set\n",
    "\n",
    "Your notebook needs to walk through these steps explicitly, in words and code, using only `Sequential` with `Dense` and `Dropout` layers. [studyx](https://studyx.ai/homework/100099923-overview-follow-the-universal-workflow-of-dlwp-4-5-1st-edition-for-a-dataset-of-your)\n",
    "\n",
    "## 2. A concrete plan using MNIST\n",
    "\n",
    "You can pick any of MNIST, IMDB, Reuters, Boston, or TFDS, but MNIST is usually the easiest. Here’s how your notebook could be structured if you choose MNIST: [github](https://github.com/ShawDa/Keras-examples/blob/master/mnist_mlp.py)\n",
    "\n",
    "1. **Title + Introduction (markdown)**\n",
    "    - Explain the task: classify 28×28 grayscale digit images into 10 classes.\n",
    "    - Explain why this is a supervised multiclass classification problem.\n",
    "\n",
    "2. **Problem and success metric (markdown + tiny code)**\n",
    "    - Problem: image classification, input = images, output = digit labels.\n",
    "    - Metric: accuracy on a held-out test set.\n",
    "\n",
    "3. **Dataset loading and preprocessing (code + a few short comments)**\n",
    "    - Load MNIST via `keras.datasets.mnist.load_data()`.\n",
    "    - Flatten to vectors of length 784, convert to float32, scale to. [sourestdeeds.github](https://sourestdeeds.github.io/pdf/Deep%20Learning%20with%20Python.pdf)\n",
    "    - One‑hot encode labels.\n",
    "    - Split training data into train/validation (e.g., 50k/10k).\n",
    "\n",
    "4. **Baseline model (code + short explanation)**\n",
    "    - Very small MLP, for example:\n",
    "        - `Dense(64, activation=\"relu\")`\n",
    "        - `Dense(10, activation=\"softmax\")`\n",
    "    - Compile with `optimizer=\"rmsprop\"`, `loss=\"categorical_crossentropy\"`, `metrics=[\"accuracy\"]`.\n",
    "    - Train for a few epochs, report train and validation accuracy.\n",
    "    - Compare to a trivial baseline (e.g. random guess ≈ 10% accuracy).\n",
    "\n",
    "5. **Overfitting model (code + explanation)**\n",
    "    - Increase model size and/or epochs:\n",
    "        - `Dense(512, activation=\"relu\")`\n",
    "        - another `Dense(512, activation=\"relu\")`\n",
    "        - `Dense(10, activation=\"softmax\")`\n",
    "    - Train longer and show training vs validation accuracy/loss.\n",
    "    - Point out signs of overfitting (training improves while validation degrades).\n",
    "\n",
    "6. **Regularized model + tuning (code + explanation)**\n",
    "    - Add `Dropout` after dense layers, maybe reduce units, change epochs, batch size.\n",
    "    - Train again and compare validation results to overfitting model.\n",
    "    - Briefly discuss what changed and why it helps generalization.\n",
    "\n",
    "7. **Final evaluation + interpretation (markdown + code)**\n",
    "    - Evaluate best model on the test set.\n",
    "    - Interpret: is performance good for the task? where might it fail?\n",
    "    - Optionally, show a small misclassification table or a couple of predictions (but no big visualization section at the beginning, as per instructions).\n",
    "\n",
    "8. **References / code credits (markdown)**\n",
    "    - Explicitly note any code you adapted from DLWP, Keras examples, or class notebooks. [kdnuggets](https://www.kdnuggets.com/2018/06/keras-4-step-workflow.html)\n",
    "\n",
    "## 3. Next step: narrow things down\n",
    "\n",
    "To keep this aligned with your course, the key is: you must narrate each workflow step in markdown, not just dump code. [studyx](https://studyx.ai/homework/100099923-overview-follow-the-universal-workflow-of-dlwp-4-5-1st-edition-for-a-dataset-of-your)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
